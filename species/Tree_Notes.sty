Tree Notes

1. Reverse Dictionary:
This is used for testing, takes a location and returns the species at that location using .get()
The code is a bit complex because it is not easy to manipulate dictionaries. Locations with no species 
had to be taken into account. The training data has no locations with no species and so the model doesnt
train for that output. This is esentially like having an extra label in the testing data = 'None', I added
the id = 0 for that label so that it can later be taken care of.

2. Data Balancing
First attempt for data balancing was taking all the datapoints and reducing the labels (species) with more 
than the mean number of locations to the mean number of locations (these were chosen at random). This improved our model
by around .02. Noteworthy because reducing data improved model - shows importance of data balancing. Also note, using 
minimum instead of mean could be a good idea... would reduced the data by a lot more.
Second attempt at data balancing is using the decision tree classifer and seeting the class_weight parameter to 'balanced'.
The results using this method were worse than when using the reduced dataset.
There might be other ways to do this, will have to keep working on it.

3. Decision Tree Classifier
- min_leaf_number: Gave the best results with n = 2 for my test accuracy, using cross validation it gives that the best value is 1
consistently.
- class_weight: Using 'balanced' I got worse results than when I balanced it myself.
- criterion: Have been using 'gini' which is the default, could try 'Entropy' and others.. havent touch it yet
- random_sate: Not sure what it does...?
- max_depth: Accuracy increases up until a max depth of 30 and then it becomes constant.


4. Predict_Proba (so that it returns probability of each class), this is just one example:
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Returns 499 0s and one 1. Uses min_leaf number = 1
For min_leaf_number = 30 I get 17/18 ids with "some" probability

4. Test_ids 
List with list of species ids, indexed such that they match the indeces of test locations.

5. Tree Plotting
Looks awful, problem with having 2 features...

6. Accuracy/Evaluation
Score method cant be used because test data has different format to train data. Hence have to be more creative. 
Model only returns one specie per location, while locations have more than one specie per location. Ideas:
- Improve model so that it returns a probability for each specie in each test location
- Accuracy, if specie predicted is in location tested = Good, if not = Bad. Ignores locations with no species.
This method gives a 0.58 accuracy but it is really misleading as it ignores many of the species in the test 
location that arent predicted.
- Confusion matrix: True positive, True Negative, False Positive and False Negative, best idea we have for our 
current model. Gives the following values:
True positive: 149125
True negative: 142215357
False positive: 138997 
False negative: 1557521
These are totals. 
I am guessing False Positive value would go down if we remove all locations with no species as in all those locations
some species are being predicted and none will be there.
Just for Turdus merulus:
True positive: 335
True negative: 277710
False positive: 1215
False negative: 8862


7. Current problems:
- Changing decision tree to random forest: Ransom forest with 10 estimates
Total True positive: 154070
Total True negative: 142220302
Total False positive: 134052
Total False negative: 1552576

Second run (using 544 data points)

True positive Turdus Merulus: 165
True negative Turdus Merulus: 278421
False positive Turdus Merulus: 504
False negative Turdus Merulus: 9032

Total True positive: 158561
Total True negative: 142224793
Total False positive: 129561
Total False negative: 1548085

Seems to do a bit better but I dont know if statistically significant?

- Changing decision tree to a multioutput model- Not possible

- Using get_proba with decision tree and seeting cutoff at 0.025.
- Balancing using mean: 544
- Get contour for decision tree

- Seems like doing the procedire of the confusion matrix using predict_proba > 0.025 is giving no 
true positives:
True positive Turdus Merulus: 0
True negative Turdus Merulus: 277196
False positive Turdus Merulus: 1728
False negative Turdus Merulus: 9197

Not sure why this is happening at the moment, would have to run it for all species to know for sure 
but seems a little weird... After running it for all species... I get very few true positives:
Total True positive w/ probs: 36405
Total True negative w/ probs: 140975034
Total False positive w/ probs: 1370893
Total False negative w/ probs: 1670142


- What is the AUC curve?
- Check teacher procedures



